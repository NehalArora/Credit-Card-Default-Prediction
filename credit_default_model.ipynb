# ======================
# 1. Import Libraries
# ======================
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
from sklearn.metrics import f1_score


# Set style
sns.set(style="whitegrid")

# ======================
# 2. Load & Balance Data
# ======================
df = pd.read_csv('Credit_Card_Default.csv')

# Undersample majority class
majority = df[df['default.payment.next.month'] == 0]
minority = df[df['default.payment.next.month'] == 1]
majority_downsampled = majority.sample(n=len(minority), random_state=42)
df_balanced = pd.concat([majority_downsampled, minority]).sample(frac=1, random_state=42).reset_index(drop=True)

# Add new features
df_balanced['AVG_PAY'] = df_balanced[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5']].mean(axis=1)
df_balanced['ANY_LATE'] = (df_balanced[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5']] > 0).any(axis=1).astype(int)

print("\nBalanced Class Distribution:\n", df_balanced['default.payment.next.month'].value_counts())

# ======================
# 3. EDA (on Balanced Data)
# ======================
plt.figure(figsize=(16, 12))
sns.heatmap(df_balanced.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.3)
plt.title('Feature Correlation Heatmap', fontsize=16)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Scatter Plot
defaulters = df_balanced[df_balanced['default.payment.next.month'] == 1]
non_defaulters = df_balanced[df_balanced['default.payment.next.month'] == 0]

plt.figure(figsize=(10, 6))
plt.scatter(non_defaulters['LIMIT_BAL'], non_defaulters['PAY_0'], color="green", label="Non-Defaulter", alpha=0.3)
plt.scatter(defaulters['LIMIT_BAL'], defaulters['PAY_0'], color="red", label="Defaulter", alpha=0.6)
plt.title("Credit Limit vs. Payment Status (Default Risk Analysis)")
plt.xlabel("Credit Limit (LIMIT_BAL)")
plt.ylabel("Most Recent Payment Status (PAY_0)")
plt.legend()
plt.grid(True)
plt.show()

# ======================
# 4. Feature Selection
# ======================
selected_features = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'LIMIT_BAL', 'AVG_PAY', 'ANY_LATE']
X = df_balanced[selected_features]
y = df_balanced['default.payment.next.month']

# ======================
# 5. Train-Test Split
# ======================
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ======================
# 6. Model Training & Evaluation
# ======================

# --- Logistic Regression (scaled) ---
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train_scaled, y_train)
y_pred_lr = lr_model.predict(X_test_scaled)

# --- Decision Tree (unscaled) ---
dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

# --- Naive Bayes (unscaled) ---
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

# ======================
# 7. Results
# ======================
print("\nðŸ”¹ Logistic Regression Metrics:")
print(classification_report(y_test, y_pred_lr))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lr))

print("\nðŸ”¹ Decision Tree Metrics:")
print(classification_report(y_test, y_pred_dt))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))

print("\nðŸ”¹ Naive Bayes Metrics:")
print(classification_report(y_test, y_pred_nb))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_nb))
